{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fTLHWGxIJX4Z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.models import shufflenet_v2_x1_0\n",
    "import timm\n",
    "from transformers import MobileViTForImageClassification, MobileViTConfig\n",
    "from transformers import ConvNextImageProcessor, ConvNextForImageClassification\n",
    "\n",
    "#Device Configurations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wdO39NWhJm1d"
   },
   "outputs": [],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, folders_with_labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folders_with_labels (list of tuples): List of (path_to_folder, class_name) pairs.\n",
    "            transform: Transform to apply to each frame.\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Build class_to_idx mapping\n",
    "        self.class_to_idx = {class_name: idx for idx, (folder, class_name) in enumerate(folders_with_labels)}\n",
    "\n",
    "        # Load data and assign labels\n",
    "        for folder, class_name in folders_with_labels:\n",
    "            label = self.class_to_idx[class_name]  # Use class_name to get the numeric label\n",
    "\n",
    "            # List all subfolders (videos) in the given folder\n",
    "            video_folders = [os.path.join(folder, subfolder) for subfolder in os.listdir(folder) if os.path.isdir(os.path.join(folder, subfolder))]\n",
    "\n",
    "            for video_folder in video_folders:\n",
    "                # Add each frame in the video folder as an independent sample\n",
    "                frame_paths = [os.path.join(video_folder, frame) for frame in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, frame))]\n",
    "                self.data.extend([(frame_path, label) for frame_path in frame_paths])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_path, label = self.data[idx]\n",
    "\n",
    "        # Open the frame as an image\n",
    "        frame = Image.open(frame_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            frame = self.transform(frame)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return frame, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "o8oPQ3V0J_6J"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, mode='min', delta=0, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait for improvement before stopping.\n",
    "            mode (str): 'min' for metrics like validation loss (smaller is better), 'max' for metrics like accuracy.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "            verbose (bool): If True, prints messages when training stops early.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif (self.mode == 'min' and current_score > self.best_score - self.delta) or \\\n",
    "             (self.mode == 'max' and current_score < self.best_score + self.delta):\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping: No improvement in {self.counter}/{self.patience} epochs.\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "9ndbVEdIhBx6"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
    "    \"\"\"\n",
    "    Trains the model using the given training dataset and evaluates it on the validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        criterion (torch.nn.Module): Loss function (e.g., BCEWithLogitsLoss for binary classification).\n",
    "        optimizer (torch.optim.Optimizer): Optimization algorithm (e.g., Adam, SGD).\n",
    "        num_epochs (int, optional): Number of training epochs. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(patience=3, mode='min', verbose=True)\n",
    "\n",
    "    # Training loop for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0  # Accumulate loss per epoch\n",
    "        correct_predictions = 0  # Track the number of correct predictions\n",
    "\n",
    "        # Iterate through batches in the training dataset\n",
    "        for frames, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            # Move data to the selected device (GPU or CPU)\n",
    "            frames, labels = frames.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass - Attempt to process inputs with different model types\n",
    "            outputs = None  # Initialize outputs to prevent unbound variable errors\n",
    "\n",
    "            try:\n",
    "                outputs = model(frames).squeeze(1)  # CNN model\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                outputs = model(frames).logits.squeeze(1)  # Transformer model\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                outputs = model(frames).logits.squeeze(-1)  # ConvNeXt-Tiny model\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            # If no valid output was generated, raise an error\n",
    "            if outputs is None:\n",
    "                raise ValueError(\"Model inference failed. Check input shapes and model compatibility.\")\n",
    "\n",
    "            # Compute loss using the specified criterion\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Zero the gradients before backpropagation\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagation: Compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update model parameters based on computed gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss for the epoch (scaled by batch size)\n",
    "            running_loss += loss.item() * frames.size(0)\n",
    "\n",
    "            # Convert logits to probabilities using the sigmoid function (for binary classification)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            # Convert probabilities to binary predictions (threshold = 0.5)\n",
    "            predicted = (probs > 0.5).float()\n",
    "\n",
    "            # Count the number of correct predictions\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Compute average training loss and accuracy for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct_predictions / len(train_loader.dataset)\n",
    "\n",
    "        # Print training results for the current epoch\n",
    "        print(f\"Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "        # ---------------- Validation Phase ----------------\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for faster validation\n",
    "            for frames, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                # Move data to the selected device\n",
    "                frames, labels = frames.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass: Compute predictions\n",
    "                outputs = None  # Initialize\n",
    "\n",
    "                try:\n",
    "                    outputs = model(frames).squeeze(1)  # CNN\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                try:\n",
    "                    outputs = model(frames).logits.squeeze(1)  # Transformer\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                try:\n",
    "                    outputs = model(frames).logits.squeeze(-1)  # ConvNeXt-Tiny\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "                if outputs is None:\n",
    "                    raise ValueError(\"Model inference failed. Check input shapes and model compatibility.\")\n",
    "\n",
    "                # Compute validation loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * frames.size(0)\n",
    "\n",
    "                # Convert logits to probabilities\n",
    "                probs = torch.sigmoid(outputs)\n",
    "\n",
    "                # Convert probabilities to binary predictions\n",
    "                predicted = (probs > 0.5).float()\n",
    "\n",
    "                # Count the number of correct predictions\n",
    "                val_correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Compute average validation loss and accuracy\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct_predictions / len(val_loader.dataset)\n",
    "\n",
    "        # Print validation results for the current epoch\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Early Stopping: Stop training if validation loss does not improve\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break  # Exit the training loop early\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "PdwTVuIhGKJc"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device=device):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        device (torch.device): Device to perform computations (CPU or GPU).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics including accuracy, precision, recall, F1-score,\n",
    "              ROC-AUC score, along with all labels and predicted probabilities for further analysis.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode (disables dropout, batch norm updates)\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize lists to store labels, predictions, and probabilities\n",
    "    all_labels = []  # Ground truth labels\n",
    "    all_preds = []   # Predicted binary labels\n",
    "    all_probs = []   # Predicted probabilities\n",
    "\n",
    "    # Disable gradient computation for efficiency (no need for backpropagation)\n",
    "    with torch.no_grad():\n",
    "        # Iterate over test batches\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            # Move inputs and labels to the selected device (GPU/CPU)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass: Obtain model outputs\n",
    "            outputs = None  # Initialize outputs to prevent unbound variable errors\n",
    "\n",
    "            # Attempt to process inputs with different model types\n",
    "            try:\n",
    "                outputs = model(inputs).squeeze(1)  # CNN Model (expects logits as direct output)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                outputs = model(inputs).logits.squeeze(1)  # Transformer Model (access logits attribute)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                outputs = model(inputs).logits.squeeze(-1)  # ConvNeXt-Tiny Model (adjust shape)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            # If outputs were not successfully set, raise an error\n",
    "            if outputs is None:\n",
    "                raise ValueError(\"Model inference failed. Check input shapes and model compatibility.\")\n",
    "\n",
    "            # Convert logits to probabilities using the sigmoid function (for binary classification)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            # Convert probabilities to binary predictions using a 0.5 threshold\n",
    "            preds = (probs > 0.5).float()\n",
    "\n",
    "            # Store results for later evaluation\n",
    "            all_labels.extend(labels.cpu().numpy())  # Convert to CPU and append\n",
    "            all_preds.extend(preds.cpu().numpy())    # Convert to CPU and append\n",
    "            all_probs.extend(probs.cpu().numpy())    # Convert to CPU and append\n",
    "\n",
    "    # Compute classification metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)  # Percentage of correct predictions\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)  # True Positives / (True Positives + False Positives)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)  # True Positives / (True Positives + False Negatives)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)  # Harmonic mean of precision and recall\n",
    "\n",
    "    # Compute ROC-AUC score (handles probability-based evaluation)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        roc_auc = None  # Undefined if only one class is present in the dataset\n",
    "\n",
    "    # Print the evaluation results\n",
    "    print(f\"Test Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall   : {recall:.4f}\")\n",
    "    print(f\"Test F1-Score : {f1:.4f}\")\n",
    "    if roc_auc is not None:\n",
    "        print(f\"Test ROC-AUC  : {roc_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"Test ROC-AUC  : Undefined (only one class present in labels)\")\n",
    "\n",
    "    # Return all metrics in a dictionary for further analysis or plotting\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'all_labels': all_labels,  # Needed for plotting the ROC curve later\n",
    "        'all_probs': all_probs     # Needed for plotting the ROC curve later\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "msGalSHPGKJd"
   },
   "outputs": [],
   "source": [
    "def reinitialize_model(model_name):\n",
    "    \"\"\"\n",
    "    Reinitializes a deep learning model based on the given model name.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model to load.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: A model with a binary classification output layer.\n",
    "\n",
    "    Notes:\n",
    "        - Supports models from `timm`, `torchvision`, `torch.hub`, and `transformers`.\n",
    "        - Modifies the last classification layer to output a single value for binary classification.\n",
    "    \"\"\"\n",
    "\n",
    "    # List of models from TIMM library (efficient pre-trained models)\n",
    "    timm_models = [\"mobilenetv2_100\", 'tiny_vit_5m_224.dist_in22k_ft_in1k', \"tf_efficientnet_lite0\"]\n",
    "\n",
    "    # Check if the requested model is in the TIMM list\n",
    "    if model_name in timm_models:\n",
    "        # Create a TIMM model with a modified classification layer\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=1)\n",
    "        return model\n",
    "\n",
    "    # Load a ShuffleNet model (from torchvision) and modify its classification head\n",
    "    if model_name == \"shufflenet_v2_x1_0\":\n",
    "        model = shufflenet_v2_x1_0(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)  # Adjust for binary classification (single neuron output)\n",
    "        return model\n",
    "\n",
    "    # Load a GhostNet model (from Huawei's Torch Hub) and modify its classifier\n",
    "    if model_name == \"ghostnet_1x\":\n",
    "        model = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)\n",
    "        model.classifier = torch.nn.Linear(model.classifier.in_features, 1)  # Adjust classifier for binary output\n",
    "        return model\n",
    "\n",
    "    # Load a MobileViT model (from Apple's transformers library) and modify configuration\n",
    "    if model_name == \"apple/mobilevit-small\":\n",
    "        # Load configuration and modify number of labels to 1 for binary classification\n",
    "        config = MobileViTConfig.from_pretrained('apple/mobilevit-small', num_labels=1)\n",
    "\n",
    "        # Load the pre-trained model with the modified configuration\n",
    "        model = MobileViTForImageClassification.from_pretrained(\n",
    "            'apple/mobilevit-small',\n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True  # Avoid errors due to size mismatch\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # Load a ConvNeXt-Tiny model (from Meta/Facebook) and modify its classifier\n",
    "    if model_name == \"facebook/convnext-tiny-224\":\n",
    "        # Load the image processor (not required for PyTorch inference but useful for pre-processing)\n",
    "        processor = ConvNextImageProcessor.from_pretrained(\"facebook/convnext-tiny-224\")\n",
    "\n",
    "        # Load the pre-trained model\n",
    "        model = ConvNextForImageClassification.from_pretrained(\"facebook/convnext-tiny-224\")\n",
    "\n",
    "        # Extract the number of input features for the classification head\n",
    "        num_features = model.classifier.in_features\n",
    "\n",
    "        # Replace the classifier with a new head for binary classification\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Flatten(),              # Flatten output to fit into the linear layer\n",
    "            nn.Linear(num_features, 1) # Single output neuron for binary classification\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # If the model name does not match any known models, print an error message\n",
    "    print(\"Model not found!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "yDDJc92JGKJe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm  # For progress visualization\n",
    "\n",
    "def process_datasets(model_name, datasets, transform=transform):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a given model on multiple datasets.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model to be used.\n",
    "        datasets (list of str): List of dataset names to process.\n",
    "        transform (callable, optional): Transformations applied to the dataset (e.g., image preprocessing).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of evaluation results (metrics) for each dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []  # Store evaluation results for each dataset\n",
    "\n",
    "    # Iterate over the list of datasets\n",
    "    for dataset_name in datasets:\n",
    "        # Initialize early stopping to prevent overfitting\n",
    "        early_stopping = EarlyStopping(patience=3, mode='min', verbose=True)\n",
    "\n",
    "        print(f\"Training on {dataset_name} dataset...\")  # Log the current dataset\n",
    "\n",
    "        # Reinitialize the model for each dataset to start with fresh weights\n",
    "        model = reinitialize_model(model_name)\n",
    "\n",
    "        # Define loss function (Binary Cross-Entropy with Logits for binary classification)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Define optimizer (AdamW with learning rate 0.001)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Load dataset using FrameDataset (expects folders with labeled frames)\n",
    "        folders_with_labels = [\n",
    "            (f\"./{dataset_name}\", \"manipulated\"),  # Manipulated (Deepfake) samples\n",
    "            ('./youtube', \"original\")  # Original (Authentic) samples\n",
    "        ]\n",
    "\n",
    "        # Create a dataset instance using the given transformations\n",
    "        dataset = FrameDataset(folders_with_labels, transform=transform)\n",
    "\n",
    "        # Split dataset into training (70%), validation (15%), and testing (15%) sets\n",
    "        train_size = int(0.7 * len(dataset))  # 70% training data\n",
    "        val_size = int(0.15 * len(dataset))   # 15% validation data\n",
    "        test_size = len(dataset) - train_size - val_size  # Remainder goes to testing\n",
    "\n",
    "        train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "        # Define batch size for DataLoaders\n",
    "        batch_size = 32\n",
    "\n",
    "        # Create DataLoaders for efficient batch processing\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "        # Move model to the selected device (GPU or CPU)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Train the model on the current dataset\n",
    "        train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)\n",
    "\n",
    "        # Evaluate the trained model on the test set and store the results\n",
    "        results.append(evaluate_model(model, test_loader))\n",
    "\n",
    "    # Return the evaluation metrics for each dataset\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "6XV6X1pwIpkh"
   },
   "outputs": [],
   "source": [
    "def plot_multiple_roc_auc_curves(results_list, model_labels=None, dataset_labels=None):\n",
    "    \"\"\"\n",
    "    Plots multiple ROC-AUC curves on the same plot with dataset names.\n",
    "\n",
    "    Args:\n",
    "        results_list (list of dicts): Each dict should contain:\n",
    "            - 'all_labels': True labels (0 or 1)\n",
    "            - 'all_probs': Predicted probabilities for the positive class\n",
    "        model_labels (list of str, optional): Names of models. Default is None.\n",
    "        dataset_labels (list of str, optional): Names of datasets. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        None (Displays the ROC-AUC plot)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for i, results in enumerate(results_list):\n",
    "        all_labels = results['all_labels']\n",
    "        all_probs = results['all_probs']\n",
    "\n",
    "        # Compute ROC curve and AUC score\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Generate label for legend\n",
    "        model_name = model_labels[i] if model_labels else f'Model {i+1}'\n",
    "        dataset_name = dataset_labels[i] if dataset_labels else f'Dataset {i+1}'\n",
    "\n",
    "        legend_label = f'{dataset_name} (AUC = {roc_auc:.4f})'\n",
    "\n",
    "        # Plot ROC Curve\n",
    "        plt.plot(fpr, tpr, lw=2, label=legend_label)\n",
    "\n",
    "    # Plot baseline (random classifier)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2, label='Chance (AUC = 0.50)')\n",
    "\n",
    "    # Configure plot\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "l6Fr1YVLJ4cx"
   },
   "outputs": [],
   "source": [
    "def plot_performance_metrics(results, dataset_names):\n",
    "    \"\"\"\n",
    "    Plots performance metrics comparison for multiple datasets.\n",
    "\n",
    "    Args:\n",
    "        results (list of dict): A list of dictionaries, where each dictionary contains metrics for a dataset.\n",
    "        dataset_names (list of str): Names of the datasets corresponding to the results.\n",
    "    \"\"\"\n",
    "    # Define metrics and colors\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']\n",
    "    colors = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "    # Extract metric values for each dataset\n",
    "    metric_values = {metric: [result[metric] for result in results] for metric in metrics}\n",
    "\n",
    "    # Bar plot settings\n",
    "    x = np.arange(len(dataset_names))  # Positions for datasets on x-axis\n",
    "    width = 0.15  # Width of each bar\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "        bars = plt.bar(x + i * width, metric_values[metric], width, label=metric.capitalize(), color=color)\n",
    "\n",
    "        # Add metric name as a label inside each bar\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,  # Center the text\n",
    "                height - 0.05,                     # Slightly below the top of the bar\n",
    "                f'{metric.capitalize()}',         # Metric name\n",
    "                ha='center', va='top', fontsize=8, color='white'\n",
    "            )\n",
    "\n",
    "    # Customize the x-axis\n",
    "    plt.yticks(np.arange(0.0, 1.1, 0.05))  # Add y-axis ticks from 0.0 to 1.0 with step 0.05\n",
    "    plt.xticks(x + width * (len(metrics) - 1) / 2, dataset_names)  # Align dataset names with bars\n",
    "    plt.xlabel(\"Dataset\")\n",
    "    plt.ylabel(\"Metric Value\")\n",
    "    plt.title(\"Performance Metrics Comparison\")\n",
    "    plt.ylim(0, 1.1)  # Limit y-axis to show all labels\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "Dj8vWjOWV9jQ"
   },
   "outputs": [],
   "source": [
    "def train_test_all_models(model_names, datasets, transform=transform):\n",
    "    \"\"\"\n",
    "    Trains and evaluates multiple models on multiple datasets.\n",
    "\n",
    "    Args:\n",
    "        model_names (list of str): List of model names to train and evaluate.\n",
    "        datasets (list of str): List of dataset names for training and evaluation.\n",
    "        transform (callable, optional): Transformations applied to datasets (e.g., image preprocessing).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are model names and values are lists of evaluation results.\n",
    "              Each entry contains evaluation metrics for each dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}  # Dictionary to store results for each model\n",
    "\n",
    "    # Iterate through each model in the provided list\n",
    "    for model in model_names:\n",
    "        print(f\"Training {model}...\")  # Log the current model being trained\n",
    "\n",
    "        # Train and evaluate the model on all datasets\n",
    "        data[model] = process_datasets(model, datasets, transform=transform)\n",
    "\n",
    "    # Return the collected evaluation results\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "swlH3ROiGKJd"
   },
   "outputs": [],
   "source": [
    "# List of model names to be used for training and evaluation\n",
    "# These models include:\n",
    "# - `mobilenetv2_100`: A lightweight CNN model from TIMM.\n",
    "# - `tiny_vit_5m_224.dist_in22k_ft_in1k`: A small Vision Transformer (ViT) model.\n",
    "# - `tf_efficientnet_lite0`: A compact version of EfficientNet designed for mobile devices.\n",
    "# - `shufflenet_v2_x1_0`: A fast, lightweight CNN optimized for mobile applications.\n",
    "# - `ghostnet_1x`: A model optimized for low-memory inference, loaded from Torch Hub.\n",
    "# - `apple/mobilevit-small`: A MobileViT model (Vision Transformer for mobile use).\n",
    "# - `facebook/convnext-tiny-224`: A small ConvNeXt model from Meta (Facebook).\n",
    "model_names = [\n",
    "    \"mobilenetv2_100\",\n",
    "    \"tiny_vit_5m_224.dist_in22k_ft_in1k\",\n",
    "    \"tf_efficientnet_lite0\",\n",
    "    \"shufflenet_v2_x1_0\",\n",
    "    \"ghostnet_1x\",\n",
    "    \"apple/mobilevit-small\",\n",
    "    \"facebook/convnext-tiny-224\"\n",
    "]\n",
    "\n",
    "# List of deepfake datasets to train and evaluate models on\n",
    "# - `Deepfakes`: A dataset containing AI-generated fake videos.\n",
    "# - `Face2Face`: A dataset using the Face2Face manipulation method.\n",
    "# - `FaceShifter`: A dataset with more realistic face-swapping techniques.\n",
    "# - `FaceSwap`: A dataset containing swapped face videos.\n",
    "# - `NeuralTextures`: A dataset that uses neural texture synthesis for face manipulation.\n",
    "datasets = [\"Deepfakes\", \"Face2Face\", \"FaceShifter\", \"FaceSwap\", \"NeuralTextures\"]\n",
    "\n",
    "# Define the transformations applied to images before feeding them into models\n",
    "# - `Resize((224, 224))`: Resizes all images to 224x224 pixels to match model input size.\n",
    "# - `ToTensor()`: Converts images to PyTorch tensors (HWC → CHW format).\n",
    "# - `Normalize(mean, std)`: Normalizes images using ImageNet mean and standard deviation.\n",
    "#   - Mean: [0.485, 0.456, 0.406] (Red, Green, Blue channel mean values).\n",
    "#   - Std:  [0.229, 0.224, 0.225] (Standard deviation for each channel).\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Transform \n",
    "transform_noisy = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.1),  # Noise before normalization\n",
    "    transforms.Lambda(lambda x: torch.clamp(x, 0, 1)),  # Keep values in valid range\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Crop \n",
    "transform_random_crop = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize to larger size first\n",
    "    transforms.RandomCrop(224),     # Randomly crop to 224×224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lighting Variations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gb7iE71vWVfi",
    "outputId": "1f0e5767-e918-45f0-e434-5c98fa683143"
   },
   "outputs": [],
   "source": [
    "data = train_test_all_models(model_names, datasets, transform=transform_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzhmFLMre1Yd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
