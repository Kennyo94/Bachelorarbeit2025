{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ecb52-a03d-4c8c-a7b7-80df2b6345fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34da285-279f-4479-b2c5-737eae6df3aa",
   "metadata": {},
   "source": [
    "### Extract Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351755c4-7030-4a45-a46f-9c785fb9e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_dir, num_frames):\n",
    "    \"\"\"\n",
    "    Extracts a fixed number of evenly spaced frames from a video.\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        output_dir (str): Directory where extracted frames will be saved.\n",
    "        num_frames (int): Number of frames to extract.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Calculate the step size (interval between extracted frames)\n",
    "    step = max(total_frames // num_frames, 1)  # Avoid division by zero\n",
    "\n",
    "    count = 0       # Current frame index\n",
    "    extracted = 0   # Number of frames extracted\n",
    "\n",
    "    while extracted < num_frames:\n",
    "        # Move to the specific frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
    "\n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop if there are no more frames to read\n",
    "\n",
    "        # Save the extracted frame as an image file\n",
    "        frame_path = os.path.join(output_dir, f\"frame_{extracted:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        # Move to the next frame position\n",
    "        count += step\n",
    "        extracted += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67c638-61bd-46c8-a267-5cb6cb8f11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_videos(root_dir, output_dir, num_frames=16):\n",
    "    \"\"\"\n",
    "    Preprocess videos from the FaceForensics++ dataset.\n",
    "    Args:\n",
    "        root_dir (str): Root directory containing the manipulated_sequences folder.\n",
    "        output_dir (str): Directory where processed frames will be saved.\n",
    "        num_frames (int): Number of frames to extract from each video.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Traverse each manipulation method (e.g., Deepfakes, FaceSwap)\n",
    "    for method in os.listdir(root_dir):\n",
    "        print(method)\n",
    "        method_path = os.path.join(root_dir, method, \"c23\", \"videos\")\n",
    "        if not os.path.isdir(method_path):\n",
    "            continue  # Skip if not a valid directory\n",
    "\n",
    "        # Create an output directory for this method\n",
    "        method_output_dir = os.path.join(output_dir, method)\n",
    "        os.makedirs(method_output_dir, exist_ok=True)\n",
    "\n",
    "        videos = os.listdir(method_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "        with tqdm(total=len(videos), desc=f\"Processing videos for {method}\", unit=\"video\") as pbar:\n",
    "                \n",
    "            # Traverse each video in the folder\n",
    "            for video_file in os.listdir(method_path):\n",
    "                video_path = os.path.join(method_path, video_file)\n",
    "                video_output_dir = os.path.join(method_output_dir, os.path.splitext(video_file)[0])\n",
    "                os.makedirs(video_output_dir, exist_ok=True)\n",
    "\n",
    "                try: \n",
    "                    extract_frames(video_path, video_output_dir, num_frames)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {video_file}: {e}\")\n",
    "\n",
    "                pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d08ff-fa9a-407b-9799-9edd9e4de001",
   "metadata": {},
   "source": [
    "### Extract Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47859a82-24a0-4931-a442-0916338424db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the YuNet face detector using an ONNX model\n",
    "face_detector = cv2.FaceDetectorYN_create(\n",
    "    \"./face_detection_yunet_2023mar.onnx\",  # Path to the ONNX model file for face detection\n",
    "    \"\",  # Empty string as no additional configurations are required\n",
    "    (320, 320),  # Input size of the face detector (width, height)\n",
    "    0.9,  # Score threshold: Minimum confidence for a detected face to be considered valid\n",
    "    0.3,  # Non-Maximum Suppression (NMS) threshold: Controls suppression of overlapping detections\n",
    "    5000  # Top-k: Limits the number of top detections retained\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b34400-6275-4f58-ba74-525a15da01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_videos(root_dir, output_dir, face_detector, margin=50):\n",
    "    \"\"\"\n",
    "    Processes all Jimages in the root directory and its subdirectories,\n",
    "    detects faces, crops them with an optional margin, and saves the results\n",
    "    in a mirrored directory structure.\n",
    "\n",
    "    Parameters:\n",
    "        root_dir (str): Path to the directory containing image files.\n",
    "        output_dir (str): Directory where cropped face images will be saved.\n",
    "        face_detector (cv2.FaceDetectorYN): Initialized OpenCV face detector.\n",
    "        margin (int): Additional pixels to include around detected faces.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Gather all .jpg files from all subdirectories\n",
    "    jpg_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith(\".jpg\"):  # Ensure case-insensitive match\n",
    "                jpg_files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "    # 2. Create a progress bar to track processing\n",
    "    pbar = tqdm(total=len(jpg_files), desc=\"Processing Frames\")\n",
    "\n",
    "    # 3. Loop through all image files and process them\n",
    "    for frame_path in jpg_files:\n",
    "        # Read the image\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:  # Skip if the image is unreadable\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        # Get image dimensions\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "        # Set input size for the face detector\n",
    "        face_detector.setInputSize((w, h))\n",
    "\n",
    "        # Detect faces in the image\n",
    "        _, faces = face_detector.detect(frame)\n",
    "\n",
    "        cropped_images = []  # List to store cropped face images\n",
    "\n",
    "        # If faces are detected, extract and crop them\n",
    "        if faces is not None and len(faces) > 0:\n",
    "            for face in faces:\n",
    "                # Extract face bounding box coordinates\n",
    "                x, y, w_box, h_box = face[:4].astype(int)\n",
    "\n",
    "                # Apply margin and ensure the cropped region remains within bounds\n",
    "                new_x = max(x - margin, 0)\n",
    "                new_y = max(y - margin, 0)\n",
    "                new_w = min(w_box + 2 * margin, w - new_x)\n",
    "                new_h = min(h_box + 2 * margin, h - new_y)\n",
    "\n",
    "                # Extract the cropped face from the image\n",
    "                cropped_face = frame[new_y:new_y+new_h, new_x:new_x+new_w]\n",
    "                cropped_images.append(cropped_face)\n",
    "\n",
    "        # Compute the corresponding output directory for saving cropped faces\n",
    "        rel_dir = os.path.relpath(os.path.dirname(frame_path), root_dir)\n",
    "        out_dir = os.path.join(output_dir, rel_dir)\n",
    "        os.makedirs(out_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "        # Save each cropped face with an index\n",
    "        base_name, ext = os.path.splitext(os.path.basename(frame_path))\n",
    "        for i, crop in enumerate(cropped_images):\n",
    "            out_path = os.path.join(out_dir, f\"{base_name}_face_{i}{ext}\")\n",
    "            cv2.imwrite(out_path, crop)  # Save the cropped face\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Close the progress bar after processing all images\n",
    "    pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
